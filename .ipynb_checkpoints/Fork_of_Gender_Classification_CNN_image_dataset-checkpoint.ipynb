{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2476655,
          "sourceType": "datasetVersion",
          "datasetId": 1498843
        },
        {
          "sourceId": 6846122,
          "sourceType": "datasetVersion",
          "datasetId": 3935781
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fork of Gender_Classification_CNN  image_dataset",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "maciejgronczynski_biggest_genderface_recognition_dataset_path = kagglehub.dataset_download('maciejgronczynski/biggest-genderface-recognition-dataset')\n",
        "trainingdatapro_gender_detection_and_classification_image_dataset_path = kagglehub.dataset_download('trainingdatapro/gender-detection-and-classification-image-dataset')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEOdsmVk5Ub0",
        "outputId": "638228c3-7667-4e1a-d089-b68f983ed3f9"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'biggest-genderface-recognition-dataset' dataset.\n",
            "Using Colab cache for faster access to the 'gender-detection-and-classification-image-dataset' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# The correct path is in the output of the cell above\n",
        "data_dir = maciejgronczynski_biggest_genderface_recognition_dataset_path + '/faces'\n",
        "\n",
        "os.listdir(data_dir)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN8JC4Q95Ub1",
        "outputId": "ab95777a-15ea-4df2-b11e-f33672efca58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['man', 'woman']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jXXK3JpQ5Ub2"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "trusted": true,
        "id": "iXy__JJC5Ub2"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# The correct path is in the output of the cell above\n",
        "data_dir = maciejgronczynski_biggest_genderface_recognition_dataset_path + '/faces'\n",
        "data_test = trainingdatapro_gender_detection_and_classification_image_dataset_path + '/test'\n",
        "\n",
        "def load_dataset(directory, validation_split=None, subset=None):\n",
        "    return tf.keras.utils.image_dataset_from_directory(\n",
        "        directory,\n",
        "        validation_split=validation_split,\n",
        "        subset=subset,\n",
        "        seed=123,\n",
        "        image_size=(SIZE, SIZE),\n",
        "        batch_size=BATCH_SIZE)\n",
        "\n",
        "train_ds = load_dataset(data_dir, validation_split=0.2, subset=\"training\")\n",
        "val_ds = load_dataset(data_dir, validation_split=0.2, subset=\"validation\")\n",
        "ds_test = load_dataset(data_test)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes:\", class_names)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ojEU4s-5Ub3",
        "outputId": "72e00f42-3518-437c-cf8a-d5599840da12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27167 files belonging to 2 classes.\n",
            "Using 21734 files for training.\n",
            "Found 27167 files belonging to 2 classes.\n",
            "Using 5433 files for validation.\n",
            "Found 80 files belonging to 2 classes.\n",
            "Classes: ['man', 'woman']\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(train_ds) * BATCH_SIZE\n",
        "val_size = len(val_ds) * BATCH_SIZE\n",
        "test_size = len(ds_test) * BATCH_SIZE\n",
        "\n",
        "print(f\"Training set size: {train_size} images\")\n",
        "print(f\"Validation set size: {val_size} images\")\n",
        "print(f\"Test set size: {test_size} images\")\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:38:23.858614Z",
          "iopub.execute_input": "2025-03-19T00:38:23.858823Z",
          "iopub.status.idle": "2025-03-19T00:38:23.865042Z",
          "shell.execute_reply.started": "2025-03-19T00:38:23.858804Z",
          "shell.execute_reply": "2025-03-19T00:38:23.86439Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gxjVq8c5Ub3",
        "outputId": "0af6dc77-8b59-4d75-fd00-a564aa4b67f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 21744 images\n",
            "Validation set size: 5440 images\n",
            "Test set size: 80 images\n",
            "Number of classes: 2\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset balancing\n",
        "men, women = [], []\n",
        "for batch, labels in train_ds:\n",
        "    for img, label in zip(batch, labels):\n",
        "        (men if label == 0 else women).append((img, label))\n",
        "\n",
        "smaller_class_size = min(len(men), len(women))\n",
        "men_reduced = random.sample(men, smaller_class_size)\n",
        "balanced_data = men_reduced + women\n",
        "random.shuffle(balanced_data)\n",
        "\n",
        "imgs, labels = zip(*balanced_data)\n",
        "imgs_tensor, labels_tensor = tf.stack(imgs), tf.convert_to_tensor(labels)\n",
        "\n",
        "balanced_train_ds = tf.data.Dataset.from_tensor_slices((imgs_tensor, labels_tensor))\n",
        "balanced_train_ds = balanced_train_ds.batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:38:23.865827Z",
          "iopub.execute_input": "2025-03-19T00:38:23.866162Z",
          "iopub.status.idle": "2025-03-19T00:38:53.973121Z",
          "shell.execute_reply.started": "2025-03-19T00:38:23.866119Z",
          "shell.execute_reply": "2025-03-19T00:38:53.972162Z"
        },
        "id": "opwT60QL5Ub4"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of images for each class before balancing\n",
        "print(f\"Number of men before balancing: {len(men)}\")\n",
        "print(f\"Number of women before balancing: {len(women)}\")\n",
        "\n",
        "# Quantity after balancing\n",
        "print(f\"Number of men after balancing: {len(men_reduced)}\")\n",
        "print(f\"Number of women after balancing: {len(women)}\")\n",
        "\n",
        "# We can also check in the final balanced dataset\n",
        "balanced_men = sum(1 for _, label in balanced_data if label == 0)\n",
        "balanced_women = sum(1 for _, label in balanced_data if label == 1)\n",
        "\n",
        "print(f\"Number of men in the balanced dataset: {balanced_men}\")\n",
        "print(f\"Number of women in the balanced dataset: {balanced_women}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:38:53.974135Z",
          "iopub.execute_input": "2025-03-19T00:38:53.974471Z",
          "iopub.status.idle": "2025-03-19T00:39:04.284907Z",
          "shell.execute_reply.started": "2025-03-19T00:38:53.974442Z",
          "shell.execute_reply": "2025-03-19T00:39:04.284029Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIPpwE3V5Ub4",
        "outputId": "b76d4448-2638-4a84-96ec-2ea1d8b48c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of men before balancing: 14173\n",
            "Number of women before balancing: 7561\n",
            "Number of men after balancing: 7561\n",
            "Number of women after balancing: 7561\n",
            "Number of men in the balanced dataset: 7561\n",
            "Number of women in the balanced dataset: 7561\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display, Image\n",
        "import random\n",
        "\n",
        "def plot_images(dataset, class_names):\n",
        "    # Convert the dataset to a list\n",
        "    images_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    # Populate lists with images and labels\n",
        "    for images, labels in dataset:\n",
        "        images_list.append(images.numpy())\n",
        "        labels_list.append(labels.numpy())\n",
        "\n",
        "    # Flatten lists for easy random selection\n",
        "    all_images = np.concatenate(images_list, axis=0)\n",
        "    all_labels = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    # Randomly select 9 images\n",
        "    random_indices = random.sample(range(len(all_images)), 9)\n",
        "\n",
        "    for i in random_indices:\n",
        "        img = all_images[i].astype(\"uint8\")  # Convert image to uint8\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert from RGB to BGR (OpenCV uses BGR)\n",
        "\n",
        "        # Convert the image to a format that IPython can display\n",
        "        _, img_encoded = cv2.imencode('.png', img)\n",
        "        img_display = img_encoded.tobytes()  # Convert to bytes\n",
        "\n",
        "        # Display the image with IPython\n",
        "        display(Image(data=img_display, format='png', width=200))\n",
        "\n",
        "        # Show the class title\n",
        "        print(f\"Class: {class_names[all_labels[i]]}\")\n",
        "\n",
        "plot_images(balanced_train_ds, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:39:04.287395Z",
          "iopub.execute_input": "2025-03-19T00:39:04.28764Z",
          "iopub.status.idle": "2025-03-19T00:39:11.39338Z",
          "shell.execute_reply.started": "2025-03-19T00:39:04.287619Z",
          "shell.execute_reply": "2025-03-19T00:39:11.392402Z"
        },
        "id": "Rx0MIGkF5Ub5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "# Create EfficientNetB0 model\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3)\n",
        ")\n",
        "print(f'Total layers in base model: {len(base_model.layers)}')\n",
        "# Freeze the base initially\n",
        "base_model.trainable = False\n",
        "inputs = layers.Input(shape=(SIZE, SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.20)(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-4, l2=1e-3))(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "# Initial compilation\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        ")\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.5,\n",
        "                              patience=5,\n",
        "                              verbose=1)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    '/content/best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "# Initial training (only the model head)\n",
        "history = model.fit(\n",
        "    balanced_train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[reduce_lr, model_checkpoint]\n",
        ")\n",
        "# Fine-Tuning: unfreeze part of the base\n",
        "print(\"\\nFine Tuning\\n\")\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        ")\n",
        "# Training with Fine-Tuning\n",
        "history_fine = model.fit(\n",
        "    balanced_train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[reduce_lr, early_stopping, model_checkpoint]\n",
        ")\n",
        "# After training, save the final model in .h5 format\n",
        "model.save('/content/final_model.h5', include_optimizer=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:39:11.395223Z",
          "iopub.execute_input": "2025-03-19T00:39:11.395479Z",
          "iopub.status.idle": "2025-03-19T00:42:52.935802Z",
          "shell.execute_reply.started": "2025-03-19T00:39:11.395457Z",
          "shell.execute_reply": "2025-03-19T00:42:52.935048Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "72x-7wcs5Ub5",
        "outputId": "a6ce061f-f805-4443-c351-4cebe85d28ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SIZE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2879267818.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create EfficientNetB0 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m base_model = tf.keras.applications.EfficientNetB0(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SIZE' is not defined"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "val_results = model.evaluate(val_ds)\n",
        "test_results = model.evaluate(ds_test)\n",
        "print(f\"Validation - Loss: {val_results[0]}, Accuracy: {val_results[1]}, AUC: {val_results[2]}\")\n",
        "print(f\"Test - Loss: {test_results[0]}, Accuracy: {test_results[1]}, AUC: {test_results[2]}\")\n",
        "# Prediction test\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def predict_sample(model, dataset, class_names):\n",
        "    for image_batch, labels_batch in dataset.take(1):\n",
        "        test_image = image_batch[0]\n",
        "        test_label = labels_batch[0]\n",
        "\n",
        "    test_image = preprocess_input(test_image)  # Normalization correction\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    prediction = model.predict(test_image)\n",
        "\n",
        "    predicted_class = \"Woman\" if prediction >= 0.5 else \"Man\"\n",
        "    true_class = class_names[int(test_label)]  # True class correction\n",
        "\n",
        "    plt.imshow(image_batch[0].numpy().astype(\"uint8\"))  # Display image correctly\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Prediction: {predicted_class} (Probability: {prediction[0][0]:.4f})\")\n",
        "    print(f\"True label: {true_class}\")\n",
        "\n",
        "predict_sample(model, train_ds, class_names)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:42:52.936829Z",
          "iopub.execute_input": "2025-03-19T00:42:52.937115Z",
          "iopub.status.idle": "2025-03-19T00:43:09.548095Z",
          "shell.execute_reply.started": "2025-03-19T00:42:52.937092Z",
          "shell.execute_reply": "2025-03-19T00:43:09.547227Z"
        },
        "id": "ERygS7p15Ub5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sample(model, train_ds, class_names)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:43:09.548923Z",
          "iopub.execute_input": "2025-03-19T00:43:09.549196Z",
          "iopub.status.idle": "2025-03-19T00:43:09.758165Z",
          "shell.execute_reply.started": "2025-03-19T00:43:09.549167Z",
          "shell.execute_reply": "2025-03-19T00:43:09.757261Z"
        },
        "id": "DqdV4fhk5Ub6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from PIL import Image\n",
        "# 📌 Load the trained model\n",
        "model = tf.keras.models.load_model(\"/content/best_model.keras\")\n",
        "# 📌 Function to load and preprocess the image\n",
        "def preprocess_image(image_path, target_size=(SIZE, SIZE)):\n",
        "    image = Image.open(image_path)  # Open image\n",
        "    image = image.resize(target_size)  # Resize\n",
        "    image = np.array(image)  # Convert to array\n",
        "    image = preprocess_input(image)  # Apply EfficientNet preprocessing\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:43:09.759062Z",
          "iopub.execute_input": "2025-03-19T00:43:09.759326Z",
          "iopub.status.idle": "2025-03-19T00:43:15.471286Z",
          "shell.execute_reply.started": "2025-03-19T00:43:09.759303Z",
          "shell.execute_reply": "2025-03-19T00:43:15.470385Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "UlEWFDML5Ub6",
        "outputId": "45622e6a-7765-4728-c7bf-710110d00a9d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=/kaggle/working/best_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4238949817.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 📌 Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/best_model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# 📌 Function to load and preprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/kaggle/working/best_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from PIL import Image\n",
        "# 📌 Load the trained model\n",
        "model = tf.keras.models.load_model(\"/content/best_model.keras\")\n",
        "# 📌 Function to load and preprocess the image\n",
        "def preprocess_image(image_path, target_size=(SIZE, SIZE)):\n",
        "    image = Image.open(image_path)  # Open image\n",
        "    image = image.resize(target_size)  # Resize\n",
        "    image = np.array(image)  # Convert to array\n",
        "    image = preprocess_input(image)  # Apply EfficientNet preprocessing\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    return image\n",
        "# 📌 Path of the image you want to test\n",
        "image_path = trainingdatapro_gender_detection_and_classification_image_dataset_path + \"/test/men/120.jpg\"\n",
        "#image_path = trainingdatapro_gender_detection_and_classification_image_dataset_path + \"/test/women/139.jpg\"\n",
        "# 📌 Load and process the image\n",
        "image = preprocess_image(image_path)\n",
        "# 📌 Make the prediction\n",
        "prediction = model.predict(image)\n",
        "# 📌 Determine the predicted class\n",
        "predicted_class = \"Woman\" if prediction >= 0.5 else \"Man\"\n",
        "# 📌 Display the image and result\n",
        "plt.imshow(Image.open(image_path))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "print(f\"Prediction: {predicted_class} (Probability: {prediction[0][0]:.4f})\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:43:15.472218Z",
          "iopub.execute_input": "2025-03-19T00:43:15.472469Z",
          "iopub.status.idle": "2025-03-19T00:43:21.968315Z",
          "shell.execute_reply.started": "2025-03-19T00:43:15.472447Z",
          "shell.execute_reply": "2025-03-19T00:43:21.967455Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "hRdQHtoz5Ub6",
        "outputId": "47124bd0-7d38-4768-c91a-b6f17e2e8882"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=/kaggle/working/best_model.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3485864320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 📌 Load the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/best_model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# 📌 Function to load and preprocess the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/kaggle/working/best_model.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model_path  = '/content/final_model.h5'\n",
        "model_test = keras.models.load_model(model_path, compile=False)\n",
        "model_test.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T00:43:44.556039Z",
          "iopub.execute_input": "2025-03-19T00:43:44.556408Z",
          "iopub.status.idle": "2025-03-19T00:43:45.55562Z",
          "shell.execute_reply.started": "2025-03-19T00:43:44.556376Z",
          "shell.execute_reply": "2025-03-19T00:43:45.554951Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "D86BwfzN5Ub6",
        "outputId": "cf192ccd-da8d-43a5-ec5b-24183b893289"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/working/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-707343248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/working/final_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/working/final_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "execution_count": 4
    }
  ]
}